{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phishing Site Detection\n",
    "\n",
    "In the Pre processing of the Data the attributes are coded into following format for application of different Classifiers \n",
    "\n",
    " \tSFH's type is nominal, range is ('1', '-1', '0')\n",
    " \tpopUpWidnow's type is nominal, range is ('-1', '0', '1')\n",
    " \tSSLfinal_State's type is nominal, range is ('1', '-1', '0')\n",
    " \tRequest_URL's type is nominal, range is ('-1', '0', '1')\n",
    " \tURL_of_Anchor's type is nominal, range is ('-1', '0', '1')\n",
    " \tweb_traffic's type is nominal, range is ('1', '0', '-1')\n",
    " \tURL_Length's type is nominal, range is ('1', '-1', '0')\n",
    " \tage_of_domain's type is nominal, range is ('1', '-1')\n",
    " \thaving_IP_Address's type is nominal, range is ('0', '1')\n",
    " \tResult's type is nominal, range is ('0', '1', '-1'))\n",
    "    \n",
    "    The  data coding is as follows:\n",
    "    \"1\"  - Legitimate Website\n",
    "    \"0\"  - Suspicious\n",
    "    \"-1\" - Malicious Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_local_path = 'C:/Users/meghna/Desktop/My_Project/Phishing Site Detection/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "phishing_data_raw = loadarff(your_local_path+\"PhishingData.arff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([(b'1', b'-1', b'1', b'-1', b'-1', b'1', b'1', b'1', b'0', b'0'),\n",
       "        (b'-1', b'-1', b'-1', b'-1', b'-1', b'0', b'1', b'1', b'1', b'1'),\n",
       "        (b'1', b'-1', b'0', b'0', b'-1', b'0', b'-1', b'1', b'0', b'1'),\n",
       "        ...,\n",
       "        (b'-1', b'0', b'-1', b'-1', b'-1', b'0', b'-1', b'-1', b'0', b'1'),\n",
       "        (b'0', b'0', b'1', b'0', b'0', b'0', b'-1', b'1', b'0', b'1'),\n",
       "        (b'1', b'0', b'1', b'1', b'1', b'0', b'-1', b'-1', b'0', b'-1')],\n",
       "       dtype=[('SFH', 'S2'), ('popUpWidnow', 'S2'), ('SSLfinal_State', 'S2'), ('Request_URL', 'S2'), ('URL_of_Anchor', 'S2'), ('web_traffic', 'S2'), ('URL_Length', 'S2'), ('age_of_domain', 'S2'), ('having_IP_Address', 'S1'), ('Result', 'S2')]),\n",
       " Dataset: Phishing\n",
       " \tSFH's type is nominal, range is ('1', '-1', '0')\n",
       " \tpopUpWidnow's type is nominal, range is ('-1', '0', '1')\n",
       " \tSSLfinal_State's type is nominal, range is ('1', '-1', '0')\n",
       " \tRequest_URL's type is nominal, range is ('-1', '0', '1')\n",
       " \tURL_of_Anchor's type is nominal, range is ('-1', '0', '1')\n",
       " \tweb_traffic's type is nominal, range is ('1', '0', '-1')\n",
       " \tURL_Length's type is nominal, range is ('1', '-1', '0')\n",
       " \tage_of_domain's type is nominal, range is ('1', '-1')\n",
       " \thaving_IP_Address's type is nominal, range is ('0', '1')\n",
       " \tResult's type is nominal, range is ('0', '1', '-1'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phishing_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(b'1', b'-1', b'1', b'-1', b'-1', b'1', b'1', b'1', b'0', b'0'),\n",
       "       (b'-1', b'-1', b'-1', b'-1', b'-1', b'0', b'1', b'1', b'1', b'1'),\n",
       "       (b'1', b'-1', b'0', b'0', b'-1', b'0', b'-1', b'1', b'0', b'1'),\n",
       "       ...,\n",
       "       (b'-1', b'0', b'-1', b'-1', b'-1', b'0', b'-1', b'-1', b'0', b'1'),\n",
       "       (b'0', b'0', b'1', b'0', b'0', b'0', b'-1', b'1', b'0', b'1'),\n",
       "       (b'1', b'0', b'1', b'1', b'1', b'0', b'-1', b'-1', b'0', b'-1')],\n",
       "      dtype=[('SFH', 'S2'), ('popUpWidnow', 'S2'), ('SSLfinal_State', 'S2'), ('Request_URL', 'S2'), ('URL_of_Anchor', 'S2'), ('web_traffic', 'S2'), ('URL_Length', 'S2'), ('age_of_domain', 'S2'), ('having_IP_Address', 'S1'), ('Result', 'S2')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selection of the Data and converting data into numpy format for flexibility in cleaning\n",
    "phishing_data_array = np.array(phishing_data_raw[0])\n",
    "phishing_data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1353, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SFH</th>\n",
       "      <th>popUpWidnow</th>\n",
       "      <th>SSLfinal_State</th>\n",
       "      <th>Request_URL</th>\n",
       "      <th>URL_of_Anchor</th>\n",
       "      <th>web_traffic</th>\n",
       "      <th>URL_Length</th>\n",
       "      <th>age_of_domain</th>\n",
       "      <th>having_IP_Address</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1353 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SFH  popUpWidnow  SSLfinal_State  Request_URL  URL_of_Anchor  \\\n",
       "0       1           -1               1           -1             -1   \n",
       "1      -1           -1              -1           -1             -1   \n",
       "2       1           -1               0            0             -1   \n",
       "3       1            0               1           -1             -1   \n",
       "4      -1           -1               1           -1              0   \n",
       "...   ...          ...             ...          ...            ...   \n",
       "1348   -1           -1              -1           -1             -1   \n",
       "1349   -1            0               1            0             -1   \n",
       "1350   -1            0              -1           -1             -1   \n",
       "1351    0            0               1            0              0   \n",
       "1352    1            0               1            1              1   \n",
       "\n",
       "      web_traffic  URL_Length  age_of_domain  having_IP_Address  Result  \n",
       "0               1           1              1                  0       0  \n",
       "1               0           1              1                  1       1  \n",
       "2               0          -1              1                  0       1  \n",
       "3               0           1              1                  0       0  \n",
       "4               0          -1              1                  0       1  \n",
       "...           ...         ...            ...                ...     ...  \n",
       "1348           -1           0              1                  0       1  \n",
       "1349            0           0              1                  0      -1  \n",
       "1350            0          -1             -1                  0       1  \n",
       "1351            0          -1              1                  0       1  \n",
       "1352            0          -1             -1                  0      -1  \n",
       "\n",
       "[1353 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the numpy array into Pandas data frame  and casting the coloumns to numeric type\n",
    "phishing_df = pd.DataFrame(phishing_data_array).apply(pd.to_numeric)\n",
    "print(phishing_df.shape)\n",
    "phishing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SFH', 'popUpWidnow', 'SSLfinal_State', 'Request_URL', 'URL_of_Anchor',\n",
      "       'web_traffic', 'URL_Length', 'age_of_domain', 'having_IP_Address',\n",
      "       'Result'],\n",
      "      dtype='object')\n",
      "Column names: SFH, popUpWidnow, SSLfinal_State, Request_URL, URL_of_Anchor, web_traffic, URL_Length, age_of_domain, having_IP_Address, Result\n",
      "[ 0  1  1 ...  1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "# Getting column names and joining them.\n",
    "col_names = phishing_df.columns\n",
    "print(col_names)\n",
    "print(\"Column names: \" + \", \".join(phishing_df.columns))\n",
    "\n",
    "# The scikit learn package takes data in form of labels and predictors\n",
    "# Extracting Result column to pass as a target column hence we are storing its values in labels\n",
    "labels = phishing_df[\"Result\"].values\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor_Columns:SFH, popUpWidnow, SSLfinal_State, Request_URL, URL_of_Anchor, web_traffic, URL_Length, age_of_domain\n",
      "[[ 1 -1  1 ...  1  1  1]\n",
      " [-1 -1 -1 ...  0  1  1]\n",
      " [ 1 -1  0 ...  0 -1  1]\n",
      " ...\n",
      " [-1  0 -1 ...  0 -1 -1]\n",
      " [ 0  0  1 ...  0 -1  1]\n",
      " [ 1  0  1 ...  0 -1 -1]]\n"
     ]
    }
   ],
   "source": [
    "predictor_cols = col_names[0:len(col_names)-2] # Selecting the predictor column names\n",
    "print(\"Predictor_Columns:\" + \", \".join(predictor_cols))\n",
    "#Extracting Predictor points \n",
    "predictors = phishing_df[predictor_cols].values\n",
    "print(predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Next, we'll make a model that will be used to predict patients. In this case, we will use different algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, labels, test_size=0.3, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 8}\n"
     ]
    }
   ],
   "source": [
    "#applying grid search to find best performing parameters \n",
    "k = np.arange(1,31,1) \n",
    "parameters = {'n_neighbors' : k}\n",
    "clf_knn = KNeighborsClassifier(weights = 'distance')\n",
    "clf = GridSearchCV(clf_knn,parameters,cv=13)\n",
    "clf_knn = clf.fit(X_train,y_train)\n",
    "print(clf_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.88      0.90       216\n",
      "           0       0.71      0.81      0.76        27\n",
      "           1       0.86      0.90      0.88       163\n",
      "\n",
      "    accuracy                           0.88       406\n",
      "   macro avg       0.83      0.86      0.85       406\n",
      "weighted avg       0.89      0.88      0.88       406\n",
      "\n",
      "[[190   4  22]\n",
      " [  3  22   2]\n",
      " [ 12   5 146]]\n",
      "Accuracy:  0.8817733990147784\n"
     ]
    }
   ],
   "source": [
    "#Prediction\n",
    "y_pred = clf_knn.predict(X_test)\n",
    "target_names = ['-1','0','1']\n",
    "\n",
    "#Classification Report\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "#Confusion Matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "#Accuracy\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now from the classification report, we can see precision has been increased for the metrics '0' & '1' and slightly decreased for '-1' but as overall performance of model is good hence we can say our model will predict just fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### With our model, we achieved 88.67% accuracy. By finetuning the hyper parameters of KNN Classifier, we can achieve more accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best leaf_size: 14\n",
      "Best p: 1\n",
      "Best n_neighbors: 10\n"
     ]
    }
   ],
   "source": [
    "#List Hyperparameters that we want to tune.\n",
    "leaf_size = list(range(1,50))\n",
    "n_neighbors = list(range(1,30))\n",
    "p=[1,2]\n",
    "\n",
    "#Converting to dictionary\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "\n",
    "#Creating new KNN object\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#Use GridSearch\n",
    "classifier = GridSearchCV(knn, hyperparameters, cv=10)\n",
    "\n",
    "#Fitting the model\n",
    "best_model = classifier.fit(X_train,y_train)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.91      0.91       216\n",
      "           0       0.71      0.44      0.55        27\n",
      "           1       0.88      0.93      0.90       163\n",
      "\n",
      "    accuracy                           0.88       406\n",
      "   macro avg       0.83      0.76      0.78       406\n",
      "weighted avg       0.88      0.88      0.88       406\n",
      "\n",
      "[[196   2  18]\n",
      " [ 12  12   3]\n",
      " [  9   3 151]]\n",
      "KNN Accuracy:  0.8842364532019704\n"
     ]
    }
   ],
   "source": [
    "#KNN Prediction\n",
    "y_pred = classifier.predict(X_test)\n",
    "target_names = ['-1','0','1']\n",
    "\n",
    "#KNN Classification Report\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "#KNN Confusion Matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "#KNN Accuracy\n",
    "knn_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"KNN Accuracy: \", knn_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accurancy =0.8923029796714006\n",
      "best parameters ={'criterion': 'gini', 'max_features': 'log2', 'n_estimators': 700}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='log2',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest\n",
    "parameters = [{'n_estimators': [100, 700],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'criterion' :['gini', 'entropy']}]\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(),  parameters,cv =5, n_jobs= -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#printing best parameters \n",
    "print(\"Best Accurancy =\" +str( grid_search.best_score_))\n",
    "print(\"best parameters =\" + str(grid_search.best_params_)) \n",
    "\n",
    "#fitting RandomForest regression with best params \n",
    "classifier = RandomForestClassifier(n_estimators = 100, criterion = \"gini\", max_features = 'log2',  random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.89      0.92       216\n",
      "           0       0.77      0.85      0.81        27\n",
      "           1       0.88      0.93      0.90       163\n",
      "\n",
      "    accuracy                           0.90       406\n",
      "   macro avg       0.86      0.89      0.88       406\n",
      "weighted avg       0.91      0.90      0.90       406\n",
      "\n",
      "[[192   4  20]\n",
      " [  3  23   1]\n",
      " [  8   3 152]]\n",
      "Random Forest Accuracy:  0.9039408866995073\n"
     ]
    }
   ],
   "source": [
    "#predicting the tests set result\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Random Forest Classification Report\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "#Random Forest Confusion Matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "#Random Forest Accuracy\n",
    "random_forest_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy: \", random_forest_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support-vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accurancy =0.8880757449178501\n",
      "best parameters ={'C': 10, 'gamma': 0.1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.2, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=0, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying grid search to find best performing parameters \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'C':[1, 10, 100, 1000], 'gamma': [ 0.1, 0.2,0.3, 0.5]}]\n",
    "grid_search = GridSearchCV(SVC(kernel='rbf' ),  parameters,cv =5, n_jobs= -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#printing best parameters \n",
    "print(\"Best Accurancy =\" +str( grid_search.best_score_))\n",
    "print(\"best parameters =\" + str(grid_search.best_params_)) \n",
    "\n",
    "#fitting kernel SVM  with best parameters calculated \n",
    "\n",
    "classifier = SVC(C=1000, kernel = 'rbf', gamma = 0.2 , random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.88      0.91       216\n",
      "           0       0.67      0.81      0.73        27\n",
      "           1       0.87      0.91      0.89       163\n",
      "\n",
      "    accuracy                           0.89       406\n",
      "   macro avg       0.83      0.87      0.84       406\n",
      "weighted avg       0.89      0.89      0.89       406\n",
      "\n",
      "[[190   6  20]\n",
      " [  3  22   2]\n",
      " [  9   5 149]]\n",
      "SVM Accuracy:  0.8891625615763546\n"
     ]
    }
   ],
   "source": [
    "#predicting the tests set result\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#SVM Classification Report\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "#SVM Confusion Matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "#SVM Accuracy\n",
    "svm_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"SVM Accuracy: \",svm_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting logistic regression \n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.88      0.87       216\n",
      "           0       0.50      0.15      0.23        27\n",
      "           1       0.81      0.88      0.84       163\n",
      "\n",
      "    accuracy                           0.83       406\n",
      "   macro avg       0.72      0.64      0.65       406\n",
      "weighted avg       0.82      0.83      0.82       406\n",
      "\n",
      "[[190   2  24]\n",
      " [ 13   4  10]\n",
      " [ 17   2 144]]\n",
      "Logistic Regression Accuracy:  0.8325123152709359\n"
     ]
    }
   ],
   "source": [
    "#predicting the tests set result\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Logistic Regression Classification Report\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "#Logistic Regression Confusion Matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "#Logistic Regression Accuracy\n",
    "logistic_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Accuracy: \", logistic_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90.394089</th>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88.916256</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88.423645</th>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83.251232</th>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model \n",
       "Score                             \n",
       "90.394089            Random Forest\n",
       "88.916256  Support Vector Machines\n",
       "88.423645                      KNN\n",
       "83.251232      Logistic Regression"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'Model': ['KNN', 'Random Forest', 'Support Vector Machines', 'Logistic Regression'],\n",
    "    'Score': [knn_accuracy*100, random_forest_accuracy*100, \n",
    "              svm_accuracy*100, logistic_accuracy*100]})\n",
    "result_data = results.sort_values(by='Score', ascending=False)\n",
    "result_data = result_data.set_index('Score')\n",
    "result_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From above data, we can see that Random Forest has come out to be the best scorer amongst all four but as we know Random Forest usually shows high score for the data it is trained on, hence we can also consider SVM or KNN models and tune them further to their best score. Next up, we can deploy our model using different deployment platforms or approches available to us Google Cloud Platform, Kubernetes, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
